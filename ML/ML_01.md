# 머신러닝 1일차

### 머신러닝 개요

- 데이터를 기반으로 패턴을 학습하고 결과를 추론하는 알고리즘 기법
- 음성/텍스트 인식, 자연어 처리 등에 사용됨

#### 머신러닝의 분류

- **지도학습**: 데이터에 대한 정답을 주고 학습시키는 방법 - 분류
  - 분류, 회귀, 시각/음성 
- **비지도학습**: 데이터에 대한 정답을 주지 않고 학습시키는 방법
  - 군집화, Auto Encoder
- **강화학습**: 에이전트가 주어진 환경에 대해 어떤 행동을 취하고, 이로부터 보상을 얻으면서 학습을 진행하는 방식

#### 머신러닝의 단점

- 데이터에 지나치게 의존적임
- 과적합의 위험이 있음 → '규제'를 이용한다.

### 머신러닝 기본

#### 데이터셋 분리

- `train_test_split(test_size, train_size, shuffle, random_state)`
  학습데이터(training data)와 테스트데이터(test data) 세트로 분리

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,
                                                    test_size=0.2,
                                                    random_state=20)

print('train data : \n', X_train)
print('train label : \n', y_train)
print('test data : \n', X_test)
print('test label : \n', y_test)
```

#### 학습, 예측, 평가

- 학습: `model.fit()`

```python
# 의사결정트리 모듈
from sklearn.tree import DecisionTreeClassifier

dt_clf = DecisionTreeClassifier(random_state = 20)

# 학습(fit)
dt_clf.fit(X_train , y_train) 
```

- 예측: `model.predict()`

예측은 학습데이터가 아닌 다른데이터(test data)를 이용하여야 한다

```python
prediction = dt_clf.predict(X_test)
print('predict\n' , prediction)
print('y_test\n'  , y_test)
```

- 예측 정확도 평가: `model.score()` 또는 `accuracy_score()`

```python
print(dt_clf.score(X_train, y_train))
```

```python
from sklearn.metrics import accuracy_score
print('예측 정확도 : {0:.2f}'.format( accuracy_score(y_test , prediction )))
```

#### 교차검증 (Cross Validation)

- KFold 방식

```python
import numpy  as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

from sklearn.model_selection import KFold

fold_iris = load_iris()

features = fold_iris.data
label    = fold_iris.target

fold_df_clf = DecisionTreeClassifier()

# 6개의 폴터 세트를 분리하여 각 폴드 세트별 정확도를 담을 리스트 생성
cv_accuracy = []
kfold = KFold(n_splits = 6)

n_iter = 0 
for train_idx , test_idx in kfold.split(features) :
    # print(train_idx , test_idx )
    X_train , X_val = features[train_idx] , features[test_idx]
    y_train , y_val = label[train_idx]    , label[test_idx]
    
    # 학습 및 예측
    fold_df_clf.fit(X_train , y_train)
    pred = fold_df_clf.predict(X_val)
    n_iter += 1 
    
    # 검증정확도 측정
    acc = np.round( accuracy_score(y_val , pred) , 4 )
    print('{} 교차 검증 정확도 : {} , 학습 데이터 크기 : {} , 검증 데이터 크기 : {}'
          .format(n_iter, acc , X_train.shape[0] , X_val.shape[0]))
    print('{} 검증 세트 인덱스 : {}'.format(n_iter , X_val.shape[0]))
    
    cv_accuracy.append(acc)


print('평균 검증 정확도 : {} ' , np.mean(cv_accuracy)) 
```

기존 KFold 는 레이블값의 분포를 반영하지 않기 때문에 상황에 따라서 예측정확도가 0

- Stratified KFold : 불균형한 분포를 가진 데이터 집합에 적용하는 CV

```python
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits = 3)
n_iter = 0 

for train_idx , test_idx in skf.split(fold_iris_df , fold_iris_df['target']) :
    n_iter += 1 
    
    label_train = fold_iris_df['target'].iloc[train_idx]
    label_val   = fold_iris_df['target'].iloc[test_idx]
    
    print('교차 검증 {}', n_iter)
    print('학습 레이블 데이터 분포\n' , label_train.value_counts() )
    print('검증 레이블 데이터 분포\n' , label_val.value_counts() )

    print()
```

```python
# 교차검증 정확도를 확인
from sklearn.model_selection import StratifiedKFold

dt_clf = DecisionTreeClassifier( random_state = 100 ) 

skf = StratifiedKFold(n_splits = 3)
n_iter = 0 
cv_accuracy = []

for train_idx , test_idx in skf.split(features , label) :
    X_train , X_val = features[train_idx] , features[test_idx]
    y_train , y_val = label[train_idx]    , label[test_idx]
    
    # 학습 , 예측
    dt_clf.fit(X_train, y_train)
    pred = dt_clf.predict(X_val)
    
    # 반복시 정확도 측정
    n_iter += 1
    acc = np.round( accuracy_score(y_val , pred) , 4 )
    print('{} 교차 검증 정확도 : {} , 학습 데이터 크기 : {} , 검증 데이터 크기 : {}'
          .format(n_iter, acc , X_train.shape[0] , X_val.shape[0]))
    print('{} 검증 세트 인덱스 : {}'.format(n_iter , X_val.shape[0]))
    
    cv_accuracy.append(acc)

print()
print('교차 검증 정확도 ' , np.round(cv_accuracy , 4) )
print('평균 검증 정확도 ' , np.mean(cv_accuracy ) ) 
```

